{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d35a184-789b-4f59-872d-b0fe94f7934e",
   "metadata": {},
   "source": [
    "# Software Information Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "20064744-b294-42d8-8104-a24b8ab12efe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PMID</th>\n",
       "      <th>article_date</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>github_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>34358294</td>\n",
       "      <td>None</td>\n",
       "      <td>Predicting correlated outcomes from molecular ...</td>\n",
       "      <td>Rauschenberger, Glaab</td>\n",
       "      <td>https://github.com/rauschenberger/joinet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>36106996</td>\n",
       "      <td>None</td>\n",
       "      <td>Multi-omic integration by machine learning (MI...</td>\n",
       "      <td>Dickinson, Aufschnaiter, Ott, Meyer</td>\n",
       "      <td>https://github.com/qdickinson/mimal-website</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>36106996</td>\n",
       "      <td>None</td>\n",
       "      <td>Multi-omic integration by machine learning (MI...</td>\n",
       "      <td>Dickinson, Aufschnaiter, Ott, Meyer</td>\n",
       "      <td>https://github.com/jessegmeyerlab/MIMaL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>36711640</td>\n",
       "      <td>2023-01-04</td>\n",
       "      <td>IsoAnalytics: A Single-cell Proteomics Web Ser...</td>\n",
       "      <td>Palmer, Koh, Zhan</td>\n",
       "      <td>https://github.com/zhanxw/Isoplexis_Data_Analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>34755837</td>\n",
       "      <td>None</td>\n",
       "      <td>Deep graph learning of inter-protein contacts.</td>\n",
       "      <td>Xie, Xu</td>\n",
       "      <td>https://github.com/zw2x/glinter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>34755837</td>\n",
       "      <td>None</td>\n",
       "      <td>Deep graph learning of inter-protein contacts.</td>\n",
       "      <td>Xie, Xu</td>\n",
       "      <td>https://github.com/zw2x/glinter/data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>37015128</td>\n",
       "      <td>2023-08-07</td>\n",
       "      <td>GradMDM: Adversarial Attack on Dynamic Networks.</td>\n",
       "      <td>Pan, Foo, Zheng, Fan, Rahmani, Ke, Liu</td>\n",
       "      <td>https://github.com/lingengfoo/GradMDM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>38532317</td>\n",
       "      <td>2024-03-26</td>\n",
       "      <td>COSAP: Comparative Sequencing Analysis Platform.</td>\n",
       "      <td>Ergun, Cinal, Bakışlı, Emül, Baysan</td>\n",
       "      <td>https://github.com/MBaysanLab/cosap/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>38532317</td>\n",
       "      <td>2024-03-26</td>\n",
       "      <td>COSAP: Comparative Sequencing Analysis Platform.</td>\n",
       "      <td>Ergun, Cinal, Bakışlı, Emül, Baysan</td>\n",
       "      <td>https://github.com/MBaysanLab/cosap-webapi/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>38532317</td>\n",
       "      <td>2024-03-26</td>\n",
       "      <td>COSAP: Comparative Sequencing Analysis Platform.</td>\n",
       "      <td>Ergun, Cinal, Bakışlı, Emül, Baysan</td>\n",
       "      <td>https://github.com/MBaysanLab/cosap_frontend/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>35642895</td>\n",
       "      <td>None</td>\n",
       "      <td>MIO: microRNA target analysis system for immun...</td>\n",
       "      <td>Monfort-Lanzas, Gronauer, Madersbacher, Schatz...</td>\n",
       "      <td>https://github.com/icbi-lab/mio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>35642895</td>\n",
       "      <td>None</td>\n",
       "      <td>MIO: microRNA target analysis system for immun...</td>\n",
       "      <td>Monfort-Lanzas, Gronauer, Madersbacher, Schatz...</td>\n",
       "      <td>https://github.com/icbi-lab/miopy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>29718142</td>\n",
       "      <td>None</td>\n",
       "      <td>hts-nim: scripting high-performance genomic an...</td>\n",
       "      <td>Pedersen, Quinlan</td>\n",
       "      <td>https://github.com/brentp/hts-nim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>29718142</td>\n",
       "      <td>None</td>\n",
       "      <td>hts-nim: scripting high-performance genomic an...</td>\n",
       "      <td>Pedersen, Quinlan</td>\n",
       "      <td>https://github.com/brentp/hts-nim-tools</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>37289797</td>\n",
       "      <td>2023-06-08</td>\n",
       "      <td>rang: Reconstructing reproducible R computatio...</td>\n",
       "      <td>Chan, Schoch</td>\n",
       "      <td>https://github.com/chainsawriot/rang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>37137232</td>\n",
       "      <td>None</td>\n",
       "      <td>pyGOMoDo: GPCRs modeling and docking with python.</td>\n",
       "      <td>Ribeiro, Giorgetti</td>\n",
       "      <td>https://github.com/rribeiro-sci/pygomodo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>37137232</td>\n",
       "      <td>None</td>\n",
       "      <td>pyGOMoDo: GPCRs modeling and docking with python.</td>\n",
       "      <td>Ribeiro, Giorgetti</td>\n",
       "      <td>https://github.com/rribeiro-sci/pygomodo/tree/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>37233198</td>\n",
       "      <td>None</td>\n",
       "      <td>Online bias-aware disease module mining with R...</td>\n",
       "      <td>Sarkar, Lucchetta, Maier, Abdrabbou, Baumbach,...</td>\n",
       "      <td>https://github.com/bionetslab/robust-web</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>37233198</td>\n",
       "      <td>None</td>\n",
       "      <td>Online bias-aware disease module mining with R...</td>\n",
       "      <td>Sarkar, Lucchetta, Maier, Abdrabbou, Baumbach,...</td>\n",
       "      <td>https://github.com/bionetslab/robust_bias_aware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>30989173</td>\n",
       "      <td>None</td>\n",
       "      <td>Biomedical image augmentation using Augmentor.</td>\n",
       "      <td>Bloice, Roth, Holzinger</td>\n",
       "      <td>https://github.com/mdbloice/Augmentor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        PMID article_date                                              title  \\\n",
       "64  34358294         None  Predicting correlated outcomes from molecular ...   \n",
       "65  36106996         None  Multi-omic integration by machine learning (MI...   \n",
       "66  36106996         None  Multi-omic integration by machine learning (MI...   \n",
       "67  36711640   2023-01-04  IsoAnalytics: A Single-cell Proteomics Web Ser...   \n",
       "68  34755837         None     Deep graph learning of inter-protein contacts.   \n",
       "69  34755837         None     Deep graph learning of inter-protein contacts.   \n",
       "70  37015128   2023-08-07   GradMDM: Adversarial Attack on Dynamic Networks.   \n",
       "71  38532317   2024-03-26   COSAP: Comparative Sequencing Analysis Platform.   \n",
       "72  38532317   2024-03-26   COSAP: Comparative Sequencing Analysis Platform.   \n",
       "73  38532317   2024-03-26   COSAP: Comparative Sequencing Analysis Platform.   \n",
       "74  35642895         None  MIO: microRNA target analysis system for immun...   \n",
       "75  35642895         None  MIO: microRNA target analysis system for immun...   \n",
       "76  29718142         None  hts-nim: scripting high-performance genomic an...   \n",
       "77  29718142         None  hts-nim: scripting high-performance genomic an...   \n",
       "78  37289797   2023-06-08  rang: Reconstructing reproducible R computatio...   \n",
       "79  37137232         None  pyGOMoDo: GPCRs modeling and docking with python.   \n",
       "80  37137232         None  pyGOMoDo: GPCRs modeling and docking with python.   \n",
       "81  37233198         None  Online bias-aware disease module mining with R...   \n",
       "82  37233198         None  Online bias-aware disease module mining with R...   \n",
       "83  30989173         None     Biomedical image augmentation using Augmentor.   \n",
       "\n",
       "                                              authors  \\\n",
       "64                              Rauschenberger, Glaab   \n",
       "65                Dickinson, Aufschnaiter, Ott, Meyer   \n",
       "66                Dickinson, Aufschnaiter, Ott, Meyer   \n",
       "67                                  Palmer, Koh, Zhan   \n",
       "68                                            Xie, Xu   \n",
       "69                                            Xie, Xu   \n",
       "70             Pan, Foo, Zheng, Fan, Rahmani, Ke, Liu   \n",
       "71                Ergun, Cinal, Bakışlı, Emül, Baysan   \n",
       "72                Ergun, Cinal, Bakışlı, Emül, Baysan   \n",
       "73                Ergun, Cinal, Bakışlı, Emül, Baysan   \n",
       "74  Monfort-Lanzas, Gronauer, Madersbacher, Schatz...   \n",
       "75  Monfort-Lanzas, Gronauer, Madersbacher, Schatz...   \n",
       "76                                  Pedersen, Quinlan   \n",
       "77                                  Pedersen, Quinlan   \n",
       "78                                       Chan, Schoch   \n",
       "79                                 Ribeiro, Giorgetti   \n",
       "80                                 Ribeiro, Giorgetti   \n",
       "81  Sarkar, Lucchetta, Maier, Abdrabbou, Baumbach,...   \n",
       "82  Sarkar, Lucchetta, Maier, Abdrabbou, Baumbach,...   \n",
       "83                            Bloice, Roth, Holzinger   \n",
       "\n",
       "                                          github_link  \n",
       "64           https://github.com/rauschenberger/joinet  \n",
       "65        https://github.com/qdickinson/mimal-website  \n",
       "66            https://github.com/jessegmeyerlab/MIMaL  \n",
       "67  https://github.com/zhanxw/Isoplexis_Data_Analysis  \n",
       "68                    https://github.com/zw2x/glinter  \n",
       "69               https://github.com/zw2x/glinter/data  \n",
       "70              https://github.com/lingengfoo/GradMDM  \n",
       "71               https://github.com/MBaysanLab/cosap/  \n",
       "72        https://github.com/MBaysanLab/cosap-webapi/  \n",
       "73      https://github.com/MBaysanLab/cosap_frontend/  \n",
       "74                    https://github.com/icbi-lab/mio  \n",
       "75                  https://github.com/icbi-lab/miopy  \n",
       "76                  https://github.com/brentp/hts-nim  \n",
       "77            https://github.com/brentp/hts-nim-tools  \n",
       "78               https://github.com/chainsawriot/rang  \n",
       "79           https://github.com/rribeiro-sci/pygomodo  \n",
       "80  https://github.com/rribeiro-sci/pygomodo/tree/...  \n",
       "81           https://github.com/bionetslab/robust-web  \n",
       "82    https://github.com/bionetslab/robust_bias_aware  \n",
       "83              https://github.com/mdbloice/Augmentor  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "import math\n",
    "import pathlib\n",
    "import shutil\n",
    "import tempfile\n",
    "\n",
    "import git\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# read example data which includes pubmed github links detected from article abstracts\n",
    "pd.read_parquet(\"../../../tests/data/examples/pubmed/pubmed_github_links.parquet\")[\n",
    "    64:84\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60573a4",
   "metadata": {},
   "source": [
    "# Lines of Code Changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "dc3cb9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_loc_changes(\n",
    "    repo_path: pathlib.Path, source: str, target: str, file_names: list[str]\n",
    ") -> dict[str, int]:\n",
    "    \"\"\"\n",
    "    Finds the total number of code lines changed for each specified file between two commits.\n",
    "\n",
    "    Args:\n",
    "        repo_path (pathlib.Path): The path to the git repository.\n",
    "        source (str): The source commit hash.\n",
    "        target (str): The target commit hash.\n",
    "        file_names (list[str]): List of file names to calculate changes for.\n",
    "\n",
    "    Returns:\n",
    "        dict[str, int]: A dictionary where the key is the filename, and the value is the lines changed (added and removed).\n",
    "    \"\"\"\n",
    "    repo = git.Repo(repo_path)\n",
    "    changes = {}\n",
    "\n",
    "    for file_name in file_names:\n",
    "        # Get the diff output for the file between the two commits\n",
    "        diff_output = repo.git.diff(source, target, \"--numstat\", \"--\", file_name)\n",
    "        lines_changed = 0\n",
    "        for line in diff_output.splitlines():\n",
    "            diff_line = line.split()\n",
    "            # Check if the line has exactly three parts: (addded,removed,file_path) and that the first two are numeric\n",
    "            if (\n",
    "                len(diff_line) == 3\n",
    "                and diff_line[0].isdigit()\n",
    "                and diff_line[1].isdigit()\n",
    "            ):\n",
    "                added, removed, _ = diff_line\n",
    "                lines_changed += int(added) + int(removed)\n",
    "\n",
    "        changes[file_name] = lines_changed\n",
    "\n",
    "    return changes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7c6929",
   "metadata": {},
   "source": [
    "# Normalized Entropy Calculation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d715ca03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_normalized_entropy(\n",
    "    repo_path: pathlib.Path,\n",
    "    source_commit: str,\n",
    "    target_commit: str,\n",
    "    file_names: list[str],\n",
    ") -> dict[str, float]:\n",
    "    \"\"\"\n",
    "    Calculates the entropy of changes in specified files between two commits,\n",
    "    inspired by Shannon's entropy formula. Normalized relative to the total lines\n",
    "    of code changes across specified files.\n",
    "\n",
    "    Args:\n",
    "        repo_path (str): The file path to the git repository.\n",
    "        source_commit (str): The git hash of the source commit.\n",
    "        target_commit (str): The git hash of the target commit.\n",
    "        file_names (list[str]): List of file names to calculate entropy for.\n",
    "\n",
    "    Returns:\n",
    "        dict[str, float]: A dictionary mapping file names to their calculated entropy.\n",
    "\n",
    "    Application of Entropy Calculation:\n",
    "        Entropy measures the uncertainty in a given system. Calculating the entropy\n",
    "        of lines of code (LoC) changed reveals the variability and complexity of\n",
    "        modifications in each file. Higher entropy values indicate more unpredictable\n",
    "        changes, helping identify potentially unstable code areas.\n",
    "\n",
    "    \"\"\"\n",
    "    loc_changes = calculate_loc_changes(\n",
    "        repo_path, source_commit, target_commit, file_names\n",
    "    )\n",
    "\n",
    "    # Calculate total lines of code changes across all specified files\n",
    "    total_changes = sum(loc_changes.values())\n",
    "\n",
    "    # Calculate the entropy for each file, relative to total changes\n",
    "    entropy_calculation = {\n",
    "        file_name: (\n",
    "            -(\n",
    "                (loc_changes[file_name] / total_changes)\n",
    "                * math.log2(\n",
    "                    loc_changes[file_name] / total_changes\n",
    "                )  # Entropy Calculation\n",
    "            )\n",
    "            if loc_changes[file_name] != 0\n",
    "            and total_changes\n",
    "            != 0  # Avoid division by zero and ensure valid entropy calculation\n",
    "            else 0.0\n",
    "        )\n",
    "        for file_name in loc_changes  # Iterate over each file in loc_changes dictionary\n",
    "    }\n",
    "    # Calculate total entropy\n",
    "    total_entropy = sum(entropy_calculation.values())\n",
    "\n",
    "    # Normalize total entropy to range [0, 1]\n",
    "    max_entropy = len(loc_changes)\n",
    "    normalized_total_entropy = total_entropy / max_entropy\n",
    "\n",
    "    return normalized_total_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7e76f8",
   "metadata": {},
   "source": [
    "# Proccess Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0a269d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_repository(repo_url: str) -> (float, int):\n",
    "    temp_dir = tempfile.mkdtemp()\n",
    "\n",
    "    try:\n",
    "        # Clone the repository\n",
    "        repo = git.Repo.clone_from(repo_url, temp_dir)\n",
    "        repo_path = pathlib.Path(temp_dir)\n",
    "\n",
    "        # Get the default branch\n",
    "        default_branch = repo.active_branch.name\n",
    "\n",
    "        # Get the first and most recent commits\n",
    "        commits = list(repo.iter_commits(default_branch))\n",
    "        first_commit = commits[-1]\n",
    "        most_recent_commit = commits[0]\n",
    "\n",
    "        # Calculate the total existence time (in days)\n",
    "        time_of_existence = (\n",
    "            most_recent_commit.committed_datetime - first_commit.committed_datetime\n",
    "        ).days\n",
    "\n",
    "        # Find all files that have been edited\n",
    "        file_names = set()\n",
    "        for commit in commits:\n",
    "            for diff in commit.diff(None):\n",
    "                if diff.a_path:\n",
    "                    file_names.add(diff.a_path)\n",
    "                if diff.b_path:\n",
    "                    file_names.add(diff.b_path)\n",
    "        file_names = list(file_names)\n",
    "\n",
    "        # Calculate the total normalized entropy\n",
    "        normalized_total_entropy = calculate_normalized_entropy(\n",
    "            repo_path, first_commit.hexsha, most_recent_commit.hexsha, file_names\n",
    "        )\n",
    "        return normalized_total_entropy, time_of_existence\n",
    "\n",
    "    finally:\n",
    "        # Delete the cloned repository\n",
    "        shutil.rmtree(temp_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0c6931",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d9c0cfd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repository: https://github.com/burtonrj/CytoPyManuscript, Normalized Total Entropy: 0.0000, Time of Existence: 1 days\n",
      "Repository: https://github.com/PhilippJunk/homelette, Normalized Total Entropy: 0.0919, Time of Existence: 750 days\n",
      "Repository: https://github.com/Benjamin-Crysup/prosynar, Normalized Total Entropy: 0.0398, Time of Existence: 836 days\n",
      "Failed to process repository https://github.com/Benjamin-Crysup/prosynar/releases/download/1: Cmd('git') failed due to: exit code(128)\n",
      "  cmdline: git clone -v -- https://github.com/Benjamin-Crysup/prosynar/releases/download/1 /tmp/tmpb4rlr5vb\n",
      "  stderr: 'Cloning into '/tmp/tmpb4rlr5vb'...\n",
      "remote: Not Found\n",
      "fatal: repository 'https://github.com/Benjamin-Crysup/prosynar/releases/download/1/' not found\n",
      "'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pumping 'stdout' of cmd(['git', 'diff', '6998f1576c9e5e421d4b8318fb00e7202f0f456e', '--abbrev=40', '--full-index', '-M', '--raw', '-z', '--no-color']) failed due to: ValueError(\"Reference at 'refs/heads/main' does not exist\")\n",
      "Exception in thread Thread-64813 (pump_stream):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/willdavidson/.pyenv/versions/3.11.0/lib/python3.11/site-packages/git/cmd.py\", line 159, in pump_stream\n",
      "    handler(line)\n",
      "  File \"/home/willdavidson/.pyenv/versions/3.11.0/lib/python3.11/site-packages/git/diff.py\", line 769, in <lambda>\n",
      "    lambda byt: cls._handle_diff_line(byt, repo, index),\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/willdavidson/.pyenv/versions/3.11.0/lib/python3.11/site-packages/git/diff.py\", line 730, in _handle_diff_line\n",
      "    diff = Diff(\n",
      "           ^^^^^\n",
      "  File \"/home/willdavidson/.pyenv/versions/3.11.0/lib/python3.11/site-packages/git/diff.py\", line 441, in __init__\n",
      "    for submodule in repo.submodules:\n",
      "                     ^^^^^^^^^^^^^^^\n",
      "  File \"/home/willdavidson/.pyenv/versions/3.11.0/lib/python3.11/site-packages/git/repo/base.py\", line 472, in submodules\n",
      "    return Submodule.list_items(self)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/willdavidson/.pyenv/versions/3.11.0/lib/python3.11/site-packages/git/util.py\", line 1283, in list_items\n",
      "    out_list.extend(cls.iter_items(repo, *args, **kwargs))\n",
      "  File \"/home/willdavidson/.pyenv/versions/3.11.0/lib/python3.11/site-packages/git/objects/submodule/base.py\", line 1623, in iter_items\n",
      "    if pc != repo.commit():\n",
      "             ^^^^^^^^^^^^^\n",
      "  File \"/home/willdavidson/.pyenv/versions/3.11.0/lib/python3.11/site-packages/git/repo/base.py\", line 709, in commit\n",
      "    return self.head.commit\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/willdavidson/.pyenv/versions/3.11.0/lib/python3.11/site-packages/git/refs/symbolic.py\", line 297, in _get_commit\n",
      "    obj = self._get_object()\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/willdavidson/.pyenv/versions/3.11.0/lib/python3.11/site-packages/git/refs/symbolic.py\", line 288, in _get_object\n",
      "    return Object.new_from_sha(self.repo, hex_to_bin(self.dereference_recursive(self.repo, self.path)))\n",
      "                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/willdavidson/.pyenv/versions/3.11.0/lib/python3.11/site-packages/git/refs/symbolic.py\", line 168, in dereference_recursive\n",
      "    hexsha, ref_path = cls._get_ref_info(repo, ref_path)\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/willdavidson/.pyenv/versions/3.11.0/lib/python3.11/site-packages/git/refs/symbolic.py\", line 278, in _get_ref_info\n",
      "    return cls._get_ref_info_helper(repo, ref_path)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/willdavidson/.pyenv/versions/3.11.0/lib/python3.11/site-packages/git/refs/symbolic.py\", line 257, in _get_ref_info_helper\n",
      "    raise ValueError(\"Reference at %r does not exist\" % ref_path)\n",
      "ValueError: Reference at 'refs/heads/main' does not exist\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/willdavidson/.pyenv/versions/3.11.0/lib/python3.11/threading.py\", line 1038, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/willdavidson/.pyenv/versions/3.11.0/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/home/willdavidson/.pyenv/versions/3.11.0/lib/python3.11/threading.py\", line 975, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/willdavidson/.pyenv/versions/3.11.0/lib/python3.11/site-packages/git/cmd.py\", line 165, in pump_stream\n",
      "    raise CommandError([f\"<{name}-pump>\"] + remove_password_if_present(cmdline), ex) from ex\n",
      "git.exc.CommandError: Cmd('<stdout-pump>') failed due to: ValueError('Reference at 'refs/heads/main' does not exist')\n",
      "  cmdline: <stdout-pump> git diff 6998f1576c9e5e421d4b8318fb00e7202f0f456e --abbrev=40 --full-index -M --raw -z --no-color\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[93], line 43\u001b[0m\n\u001b[1;32m     40\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 43\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[93], line 20\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m repo_url \u001b[38;5;129;01min\u001b[39;00m repo_urls:\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 20\u001b[0m         normalized_total_entropy, time_of_existence \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_repository\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepo_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m         entropies\u001b[38;5;241m.\u001b[39mappend(normalized_total_entropy)\n\u001b[1;32m     22\u001b[0m         times\u001b[38;5;241m.\u001b[39mappend(time_of_existence)\n",
      "Cell \u001b[0;32mIn[88], line 25\u001b[0m, in \u001b[0;36mprocess_repository\u001b[0;34m(repo_url)\u001b[0m\n\u001b[1;32m     23\u001b[0m file_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m commit \u001b[38;5;129;01min\u001b[39;00m commits:\n\u001b[0;32m---> 25\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m diff \u001b[38;5;129;01min\u001b[39;00m \u001b[43mcommit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiff\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m:\n\u001b[1;32m     26\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m diff\u001b[38;5;241m.\u001b[39ma_path:\n\u001b[1;32m     27\u001b[0m             file_names\u001b[38;5;241m.\u001b[39madd(diff\u001b[38;5;241m.\u001b[39ma_path)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.0/lib/python3.11/site-packages/git/diff.py:276\u001b[0m, in \u001b[0;36mDiffable.diff\u001b[0;34m(self, other, paths, create_patch, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m proc \u001b[38;5;241m=\u001b[39m diff_cmd(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_diff_args(args), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    275\u001b[0m diff_method \u001b[38;5;241m=\u001b[39m Diff\u001b[38;5;241m.\u001b[39m_index_from_patch_format \u001b[38;5;28;01mif\u001b[39;00m create_patch \u001b[38;5;28;01melse\u001b[39;00m Diff\u001b[38;5;241m.\u001b[39m_index_from_raw_format\n\u001b[0;32m--> 276\u001b[0m index \u001b[38;5;241m=\u001b[39m \u001b[43mdiff_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    278\u001b[0m proc\u001b[38;5;241m.\u001b[39mwait()\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m index\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.0/lib/python3.11/site-packages/git/diff.py:767\u001b[0m, in \u001b[0;36mDiff._index_from_raw_format\u001b[0;34m(cls, repo, proc)\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[38;5;66;03m# handles\u001b[39;00m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;66;03m# :100644 100644 687099101... 37c5e30c8... M    .gitignore\u001b[39;00m\n\u001b[1;32m    766\u001b[0m index: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDiffIndex\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m=\u001b[39m DiffIndex()\n\u001b[0;32m--> 767\u001b[0m \u001b[43mhandle_process_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    768\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    769\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbyt\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_diff_line\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbyt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrepo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    770\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfinalize_process\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    772\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_streams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    773\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    775\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m index\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.0/lib/python3.11/site-packages/git/cmd.py:199\u001b[0m, in \u001b[0;36mhandle_process_output\u001b[0;34m(process, stdout_handler, stderr_handler, finalizer, decode_streams, kill_after_timeout)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# FIXME: Why join? Will block if stdin needs feeding...\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m threads:\n\u001b[0;32m--> 199\u001b[0m     \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkill_after_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_alive():\n\u001b[1;32m    201\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(process, Git\u001b[38;5;241m.\u001b[39mAutoInterrupt):\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.0/lib/python3.11/threading.py:1112\u001b[0m, in \u001b[0;36mThread.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1109\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot join current thread\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1112\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_for_tstate_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1113\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1114\u001b[0m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[1;32m   1115\u001b[0m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[1;32m   1116\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.0/lib/python3.11/threading.py:1132\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mlock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1133\u001b[0m         lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m   1134\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Read the parquet file\n",
    "    df = pd.read_parquet(\n",
    "        \"../../../tests/data/examples/pubmed/pubmed_github_links.parquet\"\n",
    "    )\n",
    "\n",
    "    # Extract the repository URLs from the DataFrame\n",
    "    repo_urls = df[\"github_link\"].iloc[100:120].tolist()\n",
    "\n",
    "    entropies = []\n",
    "    times = []\n",
    "\n",
    "    for repo_url in repo_urls:\n",
    "        try:\n",
    "            normalized_total_entropy, time_of_existence = process_repository(repo_url)\n",
    "            entropies.append(normalized_total_entropy)\n",
    "            times.append(time_of_existence)\n",
    "            print(\n",
    "                f\"Repository: {repo_url}, Normalized Total Entropy: {normalized_total_entropy:.4f}, Time of Existence: {time_of_existence} days\"\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to process repository {repo_url}: {e}\")\n",
    "\n",
    "    # Plotting with Seaborn and Matplotlib\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.scatterplot(\n",
    "        x=times, y=entropies, s=100, alpha=0.8, color=\"blue\", edgecolor=\"black\"\n",
    "    )  # Customizing markers\n",
    "    plt.title(\"Repository Entropy vs. Time of Existence\", fontsize=16)\n",
    "    plt.xlabel(\"Time of Existence (days)\", fontsize=14)\n",
    "    plt.ylabel(\"Normalized Total Entropy\", fontsize=14)\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
